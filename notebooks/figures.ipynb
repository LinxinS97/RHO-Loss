{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223fbcee-c1be-4bf7-8a77-2aef9d343df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "\n",
    "import functools\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "plt.rcParams[\"font.weight\"] = \"light\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33dcb8b3-429c-4a50-b71b-ea1999be8c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAABICAYAAAAZFJRnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAACmklEQVR4nO3cvWoUURzG4TOaFWJhRIzxC22MjTZCLiNWNha5Agtvwlp7baxsrKysLLwALSQ2AdMIFmIkhULAIsd+KxdyPDvzPk85LOH9wxY/mLBDrbUAAKQ41XsAAMD/JH4AgCjiBwCIIn4AgCjiBwCIIn4AgCgri3x4WD1Xy9pGqy3d3Z3t957Q1OfTl3pPaObO7++9JzR1PLvde0JTdfaz94Smzp651ntCUz/+HPae0MyF89P+bn492uw9oanDL58Oaq3r88+HRX7nZ7i8WYedZyc6bJnsX3/Qe0JTt9Ye957QzO77p70nNHV09V3vCU0dX3nVe0JT92486T2hqeff3vSe0MzD+y97T2jq0e7b3hOaer298bHWujX/3GsvACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAoogfACCK+AEAogy11n//8DD8KqXstZvT3cVSykHvEY1M+bZS3Dd27huvKd9WivvG7matdX3+4cqCf2Sv1rp1QoOWzjAMH6Z635RvK8V9Y+e+8ZrybaW4b6q89gIAoogfACDKovHzosmK5THl+6Z8WynuGzv3jdeUbyvFfZO00D88AwCMnddeAEAU8QMARBE/AEAU8QMARBE/AECUv6HncpP4uwZeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# establish and plot colorblind color pallete\n",
    "colors = sns.color_palette('colorblind')\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca376f-6688-4114-b7c9-f59a2afec955",
   "metadata": {},
   "source": [
    "# Weights and Biases API Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c983e23c-9903-4d1d-9746-c2341db34959",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api(timeout=30)\n",
    "\n",
    "@functools.lru_cache(maxsize=2048)\n",
    "def extract_run_df(run, keys):\n",
    "    keys_to_extract = keys\n",
    "    set_keys_to_extract = set(keys)\n",
    "    \n",
    "    extracted_information = []\n",
    "    for row in run.scan_history(list(keys)):\n",
    "        extracted_row = {}\n",
    "        if len(set(row.keys()).intersection(set_keys_to_extract)) > 1:\n",
    "            for key in keys_to_extract:\n",
    "                if key in row.keys():\n",
    "                    extracted_row[key] = row[key]\n",
    "\n",
    "            extracted_information.append(extracted_row)\n",
    "    \n",
    "    run_df = pd.DataFrame(extracted_information)\n",
    "#     run_df = run_df.rename({\"_step\": \"step\"}, axis=1)\n",
    "    \n",
    "    return run_df\n",
    "\n",
    "def filter_runs_by_tag(tag, all_runs):\n",
    "    filtered_runs = [run for run in all_runs if tag in run.tags]\n",
    "    return filtered_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f416b-1646-4dde-ab6c-be16526fbac9",
   "metadata": {},
   "source": [
    "# More Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231b5982-7210-46ae-b69b-6e15f7c372f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cinic10_name_to_select_method_dict = {\n",
    "    \"uniform\": \"Uniform Sampling\", \n",
    "    \"_reducible_loss\": \"Reducible Loss (Ours)\",\n",
    "    \"importance_sampling\": \"Gradient Norm IS\",\n",
    "    \"_irreducible_loss\": \"Irreducible Loss\", \n",
    "    \"_gradnorm_ub\": \"Gradient Norm\", \n",
    "    \"_loss\": \"Loss\",\n",
    "}\n",
    "\n",
    "selection_methods = [\"Reducible Loss (Ours)\", \"Uniform Sampling\", \n",
    "                     \"Irreducible Loss\", \"Gradient Norm\", \"Loss\", \"SVP\",  \"Gradient Norm IS\"]\n",
    "\n",
    "selection_methods_color_dict = {\n",
    "    \"Reducible Loss (Ours)\": colors[0], \n",
    "    \"Reducible Loss (Ours)\\nSmall Irrloss Model\": colors[0], \n",
    "    \"Uniform Sampling\": colors[1], \n",
    "    \"Irreducible Loss\": colors[2],\n",
    "    \"Irreducible Loss\\nSmall Irrloss Model\": colors[2],\n",
    "    \"Gradient Norm\": colors[3],\n",
    "    \"Loss\": colors[4],\n",
    "    \"SVP\": colors[5],\n",
    "    \"Gradient Norm IS\": colors[6]\n",
    "}\n",
    "\n",
    "metrics_color_dict = {\n",
    "    \"Reducible Loss\": colors[0], \n",
    "    \"Gradient Norm\": colors[3],\n",
    "    \"Loss\": colors[4],\n",
    "}\n",
    "\n",
    "def str_to_selection_method_from_dict(string, name_dict):\n",
    "    for k, v in name_dict.items():\n",
    "        if k in string:\n",
    "            return v\n",
    "        \n",
    "def run_to_selection_method(run):\n",
    "    if run.config[\"logger/wandb/project\"] == \"svp_final\":\n",
    "        return \"SVP\"\n",
    "    elif run.config[\"model/_target_\"] == \"src.models.ImportanceSamplingModel.ImportanceSamplingModel\":\n",
    "        return \"Gradient Norm IS\"\n",
    "    else:\n",
    "        name_dict  = {\n",
    "            \"src.curricula.selection_methods.uniform_selection\": \"Uniform Sampling\", \n",
    "            \"src.curricula.selection_methods.reducible_loss_selection\": \"Reducible Loss (Ours)\", \n",
    "            \"src.curricula.selection_methods.irreducible_loss_selection\": \"Irreducible Loss\", \n",
    "            \"src.curricula.selection_methods.gradnorm_ub_selection\": \"Gradient Norm\", \n",
    "            \"src.curricula.selection_methods.ce_loss_selection\": \"Loss\"\n",
    "        }\n",
    "        return str_to_selection_method_from_dict(run.config[\"selection_method/_target_\"], name_dict)\n",
    "        \n",
    "def df_to_xvals(df):\n",
    "    return df[\"trainer/global_step\"].to_numpy()\n",
    "\n",
    "def compute_speedup(runs_all_info, baseline_name, ours_name):\n",
    "    baseline_dfs = [d for _, c, d in runs_all_info if c == baseline_name]\n",
    "    ours_dfs = [d for _, c, d in runs_all_info if c == ours_name]\n",
    "            \n",
    "    x_vals_baseline = df_to_xvals(baseline_dfs[0])\n",
    "    y_vals_baseline = np.zeros(shape=(x_vals_baseline.size, len(baseline_dfs)))\n",
    "    for sm_df_i, sm_df in enumerate(baseline_dfs):\n",
    "        acc_baseline = 100*sm_df[\"val_acc_epoch\"].to_numpy()\n",
    "        y_vals_baseline[:acc_baseline.size, sm_df_i] = acc_baseline\n",
    "    \n",
    "    x_vals_ours = df_to_xvals(ours_dfs[0])\n",
    "    y_vals_ours = np.zeros(shape=(x_vals_ours.size, len(ours_dfs)))\n",
    "    for sm_df_i, sm_df in enumerate(ours_dfs):\n",
    "        acc_ours = 100*sm_df[\"val_acc_epoch\"].to_numpy()\n",
    "        y_vals_ours[:acc_ours.size, sm_df_i] = acc_ours\n",
    "    \n",
    "    baseline_max = np.max(np.mean(y_vals_baseline, axis=-1))\n",
    "    baseline_max_step = x_vals_baseline[np.argmax(np.mean(y_vals_baseline, axis=-1))]\n",
    "    \n",
    "    steps_outperformed = np.zeros(shape=len(ours_dfs))\n",
    "    for run_i in range(len(ours_dfs)):\n",
    "        nzs = np.nonzero(y_vals_ours[:, run_i] > baseline_max)[0]\n",
    "        if len(nzs) > 0:\n",
    "            indx = nzs[0]\n",
    "            steps_outperformed[run_i] = x_vals_ours[indx]\n",
    "        else:\n",
    "            steps_outperformed[run_i] = np.inf\n",
    "            \n",
    "    return(np.mean(baseline_max_step)/np.mean(steps_outperformed))\n",
    "\n",
    "def get_runs_by_tag_quick(project, tag):\n",
    "#     api = wandb.Api(timeout=30)\n",
    "    runs = api.runs(path=project, filters={\"tags\": tag})\n",
    "    return list(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea4700a-99b7-4a63-8596-df38a8c9d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_to_dataset(run):\n",
    "    if \"CINIC10\" in run.config[\"datamodule\"]:\n",
    "        return \"CINIC10\"\n",
    "    elif \"CIFAR100\" in run.config[\"datamodule\"]:\n",
    "        return \"CIFAR100\"\n",
    "    elif \"CIFAR10\" in run.config[\"datamodule\"]:\n",
    "        return \"CIFAR10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7f605-11e3-4a2f-a8f5-787a5e9bd939",
   "metadata": {},
   "source": [
    "# Figure 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef308bc-02e1-45bf-af85-99b2f3f87a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_1a_runs = [*filter_runs_by_tag(\"figure_1a\", api.runs(\"goldiprox/cinic10\")), \n",
    "                  *filter_runs_by_tag(\"figure_1a\", api.runs(\"goldiprox/jb_cifar10\")),\n",
    "                  *filter_runs_by_tag(\"figure_1a\", api.runs(\"goldiprox/cifar100\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a061f-ba38-4f9c-abf9-c97224f6f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_reducible_loss_epoch\", \n",
    "       \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_loss_epoch\",\n",
    "       \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_grad_norm_epoch\"]\n",
    "\n",
    "figure1a_all_info = list(zip(figure_1a_runs, \n",
    "                             [run_to_dataset(r) for r in figure_1a_runs], \n",
    "                             [extract_run_df(r, tuple(keys)) for r in figure_1a_runs]))# convert keys to tuple to allow LRU cache to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117119c-1372-49f8-be5b-41b033e7572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5.75, 3), dpi=300)\n",
    "datasets = [\"CIFAR10\", \"CIFAR100\", \"CINIC10\"]\n",
    "dataset_xvals = [1, 3, 5]\n",
    "bars = [\"Reducible Loss\", \"Loss\", \"Gradient Norm\"]\n",
    "x_offset = [-0.5, 0, 0.5]\n",
    "\n",
    "key_bar_dict = {\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_reducible_loss_epoch\": \"Reducible Loss\",\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_loss_epoch\": \"Loss\",\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_grad_norm_epoch\": \"Gradient Norm\"\n",
    "}\n",
    "\n",
    "n_max_miniepoch = 150\n",
    "\n",
    "\n",
    "for run, dataset, run_df in figure1a_all_info:\n",
    "    dataset_xval = dataset_xvals[datasets.index(dataset)]\n",
    "    for k, v in key_bar_dict.items():\n",
    "        val = run_df[k].to_numpy()[:n_max_miniepoch].mean()\n",
    "        xshift = x_offset[bars.index(v)]\n",
    "        label = v if dataset == \"CIFAR10\" else None\n",
    "        \n",
    "        plt.bar(dataset_xval+xshift, 100*val, 0.5, color=metrics_color_dict[v], label=label)\n",
    "\n",
    "plt.plot([-5, 10], [20, 20], 'k--', linewidth=0.5)\n",
    "plt.legend(fontsize=7, shadow=True, fancybox=True, loc=\"upper center\", bbox_to_anchor=(.5, -0.25), title=\"Statistic\", title_fontsize=8, ncol=2)\n",
    "plt.ylabel(\"Proportion of total batch statistic\\naccounted for by top 20% of points\", fontsize=10)\n",
    "plt.ylim([0, 100])\n",
    "plt.xticks(dataset_xvals, datasets, fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlim([0, 6])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure_outputs/figure_1a.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa8163-f5a9-4516-86b3-53c6e6e50680",
   "metadata": {},
   "source": [
    "# Figure 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72a492-71b9-40c9-8fe0-0ccc300432b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"selected_percentage_corrupted_epoch\"]\n",
    "figure_1b_runs = api.runs(\"goldiprox/label_noise_1b\")\n",
    "figure1b_all_info = list(zip(figure_1b_runs, [run_to_selection_method(r) for r in figure_1b_runs], \n",
    "                             [run_to_dataset(r) for r in figure_1b_runs],\n",
    "                             [extract_run_df(r, tuple(keys)) for r in figure_1b_runs]))# convert keys to tuple to allow LRU cache to be used\n",
    "\n",
    "figure_1b_small_runs = filter_runs_by_tag(\"figure_1b\", api.runs(\"goldiprox/small_irrloss_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62080ff1-6f4a-49dd-bdfc-6d6120d1aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1b_all_info.extend(\n",
    "    list(zip(figure_1b_small_runs, [f\"{run_to_selection_method(r)}\\nSmall Irrloss Model\" for r in figure_1b_small_runs], \n",
    "                             [run_to_dataset(r) for r in figure_1b_small_runs],\n",
    "                             [extract_run_df(r, tuple(keys)) for r in figure_1b_small_runs]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96f30c-9f5a-43fb-b33a-cc1cd6d22d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_miniepoch = 150\n",
    "fig = plt.figure(figsize=(5.25, 2.5), dpi=300)\n",
    "\n",
    "datasets = [\"CIFAR10\", \"CIFAR100\", \"CINIC10\"]\n",
    "dataset_xvals = [1, 3, 5]\n",
    "selection_methods = [\"Reducible Loss (Ours)\", \"Uniform Sampling\", \n",
    "                     \"Irreducible Loss\", \"Gradient Norm\", \"Loss\",\n",
    "                     \"Reducible Loss (Ours)\\nSmall Irrloss Model\",\n",
    "                    \"Irreducible Loss\\nSmall Irrloss Model\"]\n",
    "x_offset = [-0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6]\n",
    "\n",
    "for sm_i, sm in enumerate(selection_methods):\n",
    "    for d_i, dataset in enumerate(datasets):\n",
    "        sm_dfs = [df for _, sm_e, dataset_e, df in figure1b_all_info if sm_e == sm and dataset_e == dataset]\n",
    "        dataset_xval = dataset_xvals[datasets.index(dataset)]\n",
    "        if len(sm_dfs) > 0:\n",
    "            xshift = x_offset[selection_methods.index(sm)]\n",
    "            mean_corrupted = np.mean([sm_df[\"selected_percentage_corrupted_epoch\"].to_numpy()[:n_max_miniepoch].mean() for sm_df in sm_dfs])\n",
    "            label = sm if d_i == 0 else None\n",
    "            plt.bar(dataset_xval+xshift, 100*mean_corrupted, color=selection_methods_color_dict[sm], width=0.2, label=label, \n",
    "                    hatch=\"///\" if \"Small\" in sm else None, edgecolor=\"white\")\n",
    "\n",
    "plt.plot([-5, 10], [10, 10], 'k--', linewidth=0.5)\n",
    "plt.legend(fontsize=7, shadow=True, fancybox=True, loc=\"upper left\", \n",
    "           bbox_to_anchor=(1.01, 1.01), title=\"Selection Method\", title_fontsize=8)\n",
    "plt.ylabel(\"Proportion of selected points\\nthat had label noise applied\", fontsize=10)\n",
    "plt.ylim([0, 30])\n",
    "plt.xticks(dataset_xvals, datasets, fontsize=8)\n",
    "plt.xlim([0, 6])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure_outputs/figure_1b.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8ef66-02b1-44d2-bded-4af1de82a44a",
   "metadata": {},
   "source": [
    "# Figure 1 Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc40df-05cc-498e-910b-31d9e11d7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 2.5), dpi=300)\n",
    "plt.subplot(121)\n",
    "datasets = [\"CIFAR10\", \"CIFAR100\", \"CINIC10\"]\n",
    "dataset_xvals = [1, 3, 5]\n",
    "bars = [\"Reducible Loss\", \"Loss\", \"Gradient Norm\"]\n",
    "x_offset = [-0.5, 0, 0.5]\n",
    "\n",
    "key_bar_dict = {\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_reducible_loss_epoch\": \"Reducible Loss\",\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_loss_epoch\": \"Loss\",\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_grad_norm_epoch\": \"Gradient Norm\"\n",
    "}\n",
    "\n",
    "n_max_miniepoch = 150\n",
    "\n",
    "\n",
    "for run, dataset, run_df in figure1a_all_info:\n",
    "    dataset_xval = dataset_xvals[datasets.index(dataset)]\n",
    "    for k, v in key_bar_dict.items():\n",
    "        val = run_df[k].to_numpy()[:n_max_miniepoch].mean()\n",
    "        xshift = x_offset[bars.index(v)]\n",
    "        label = v if dataset == \"CIFAR10\" else None\n",
    "        \n",
    "        plt.bar(dataset_xval+xshift, 100*val, 0.5, color=metrics_color_dict[v], label=label)\n",
    "\n",
    "plt.plot([-5, 10], [20, 20], 'k--', linewidth=0.5)\n",
    "# plt.legend(fontsize=7, shadow=True, fancybox=True, loc=\"upper center\", bbox_to_anchor=(.5, -0.25), title=\"Statistic\", title_fontsize=8, ncol=2)\n",
    "plt.ylabel(\"Proportion of total batch statistic\\naccounted for by top 20% of points (%)\", fontsize=10)\n",
    "plt.ylim([0, 100])\n",
    "plt.xticks(dataset_xvals, datasets, fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlim([0, 6])\n",
    "\n",
    "plt.subplot(122)\n",
    "datasets = [\"CIFAR10\", \"CIFAR100\", \"CINIC10\"]\n",
    "dataset_xvals = [1, 3, 5]\n",
    "selection_methods = [\"Reducible Loss (Ours)\", \"Uniform Sampling\", \n",
    "                     \"Irreducible Loss\", \"Gradient Norm\", \"Loss\",\n",
    "                     \"Reducible Loss (Ours)\\nSmall Irrloss Model\",\n",
    "                    \"Irreducible Loss\\nSmall Irrloss Model\"]\n",
    "x_offset = [-0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6]\n",
    "\n",
    "for sm_i, sm in enumerate(selection_methods):\n",
    "    for d_i, dataset in enumerate(datasets):\n",
    "        sm_dfs = [df for _, sm_e, dataset_e, df in figure1b_all_info if sm_e == sm and dataset_e == dataset]\n",
    "        dataset_xval = dataset_xvals[datasets.index(dataset)]\n",
    "        if len(sm_dfs) > 0:\n",
    "            xshift = x_offset[selection_methods.index(sm)]\n",
    "            mean_corrupted = np.mean([sm_df[\"selected_percentage_corrupted_epoch\"].to_numpy()[:n_max_miniepoch].mean() for sm_df in sm_dfs])\n",
    "            label = sm if d_i == 0 else None\n",
    "            plt.bar(dataset_xval+xshift, 100*mean_corrupted, color=selection_methods_color_dict[sm], width=0.2, label=label, \n",
    "                    hatch=\"///\" if \"Small\" in sm else None, edgecolor=\"white\")\n",
    "\n",
    "plt.plot([-5, 10], [10, 10], 'k--', linewidth=0.5)\n",
    "plt.ylabel(\"Proportion of selected points\\nthat had label noise applied (%)\", fontsize=10)\n",
    "plt.ylim([0, 30])\n",
    "plt.xticks(dataset_xvals, datasets, fontsize=8)\n",
    "plt.xlim([0, 6])\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=8, shadow=True, fancybox=True, loc=\"upper center\", \n",
    "           bbox_to_anchor=(-.25, -0.15), title=\"Selection Method\", title_fontsize=10, ncol=4)\n",
    "plt.savefig(\"figure_outputs/figure_1_combined_full.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0db1b5-2a9d-4bc3-a96e-d39273cbfd11",
   "metadata": {},
   "source": [
    "# Figure 1 – compact version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33a76d-c415-4524-ad25-4b7c31a535d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1b_all_info = list(zip(figure_1b_runs, [run_to_selection_method(r) for r in figure_1b_runs], \n",
    "                             [run_to_dataset(r) for r in figure_1b_runs],\n",
    "                             [extract_run_df(r, tuple(keys)) for r in figure_1b_runs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7beabb4-d592-4581-9dd5-2fa61fbfaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 2.25), dpi=300)\n",
    "plt.subplot(121)\n",
    "datasets = [\"CIFAR10\", \"CIFAR100\", \"CINIC10\"]\n",
    "dataset_xvals = [1, 3, 5]\n",
    "bars = [\"Reducible Loss\", \"Loss\", \"Gradient Norm\"]\n",
    "x_offset = [-0.5, 0, 0.5]\n",
    "\n",
    "key_bar_dict = {\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_reducible_loss_epoch\": \"Reducible Loss\",\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_loss_epoch\": \"Loss\",\n",
    "    \"proportion_of_total_batch_loss_corresponding_to_the_top_20%_points_with_highest_grad_norm_epoch\": \"Gradient Norm\"\n",
    "}\n",
    "\n",
    "n_max_miniepoch = 150\n",
    "\n",
    "\n",
    "for run, dataset, run_df in figure1a_all_info:\n",
    "    dataset_xval = dataset_xvals[datasets.index(dataset)]\n",
    "    for k, v in key_bar_dict.items():\n",
    "        val = run_df[k].to_numpy()[:n_max_miniepoch].mean()\n",
    "        xshift = x_offset[bars.index(v)]\n",
    "        label = v if dataset == \"CIFAR10\" else None\n",
    "        \n",
    "        plt.bar(dataset_xval+xshift, 100*val, 0.5, color=metrics_color_dict[v], label=label)\n",
    "\n",
    "plt.plot([-5, 10], [20, 20], 'k--', linewidth=0.5)\n",
    "# plt.legend(fontsize=7, shadow=True, fancybox=True, loc=\"upper center\", bbox_to_anchor=(.5, -0.25), title=\"Statistic\", title_fontsize=8, ncol=2)\n",
    "plt.ylabel(\"Proportion of sum across batch\\nfor which the top 20% of points\\nare responsible (%)\", fontsize=10)\n",
    "plt.ylim([0, 100])\n",
    "plt.xticks(dataset_xvals, datasets, fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlim([0, 6])\n",
    "\n",
    "plt.subplot(122)\n",
    "datasets = [\"CIFAR10\", \"CIFAR100\", \"CINIC10\"]\n",
    "dataset_xvals = [1, 3, 5]\n",
    "selection_methods = [\"Reducible Loss (Ours)\", \"Uniform Sampling\", \n",
    "                     \"Irreducible Loss\", \"Gradient Norm\", \"Loss\",\n",
    "                     \"Reducible Loss (Ours)\\nSmall Irrloss Model\",\n",
    "                    \"Irreducible Loss\\nSmall Irrloss Model\"]\n",
    "x_offset = [-0.6, -0.3, 0, 0.3, 0.6]\n",
    "\n",
    "for sm_i, sm in enumerate(selection_methods):\n",
    "    for d_i, dataset in enumerate(datasets):\n",
    "        sm_dfs = [df for _, sm_e, dataset_e, df in figure1b_all_info if sm_e == sm and dataset_e == dataset]\n",
    "        dataset_xval = dataset_xvals[datasets.index(dataset)]\n",
    "        if len(sm_dfs) > 0:\n",
    "            xshift = x_offset[selection_methods.index(sm)]\n",
    "            mean_corrupted = np.mean([sm_df[\"selected_percentage_corrupted_epoch\"].to_numpy()[:n_max_miniepoch].mean() for sm_df in sm_dfs])\n",
    "            label = sm if d_i == 0 else None\n",
    "            plt.bar(dataset_xval+xshift, 100*mean_corrupted, color=selection_methods_color_dict[sm], width=0.3, label=label, \n",
    "                    hatch=\"///\" if \"Small\" in sm else None, edgecolor=\"white\")\n",
    "\n",
    "plt.plot([-5, 10], [10, 10], 'k--', linewidth=0.5)\n",
    "plt.ylabel(\"Proportion of selected points\\nthat had label noise applied (%)\", fontsize=10)\n",
    "plt.ylim([0, 40])\n",
    "plt.xticks(dataset_xvals, datasets, fontsize=8)\n",
    "plt.xlim([0, 6])\n",
    "plt.tight_layout(pad=1.01)\n",
    "plt.legend(fontsize=8, shadow=True, fancybox=True, loc=\"upper right\", title=\"Selection Method\", title_fontsize=10, ncol=1, bbox_to_anchor=(1.1, 1.15))\n",
    "plt.savefig(\"figure_outputs/figure_1_combined_compact.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49346382-2662-4cab-93cf-956347bfd774",
   "metadata": {},
   "source": [
    "# Figure 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf156a5-9d87-4f58-b5ef-9404ac6e79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_methods = [\"Reducible Loss (Ours)\", \"Uniform Sampling\", \n",
    "                     \"Irreducible Loss\", \"Gradient Norm\", \"Loss\", \"SVP\",  \"Gradient Norm IS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7cdfe-1078-4218-b345-d5854169af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"val_acc_epoch\"]\n",
    "\n",
    "cifar10_runs_2a = [*filter_runs_by_tag(\"cifar10\", api.runs(\"goldiprox/jb_cifar10\")), *filter_runs_by_tag(\"cifar10\", api.runs(\"goldiprox/svp_final\"))]\n",
    "cifar10_runs_all_info = list(zip(cifar10_runs_2a, [run_to_selection_method(r) for r in cifar10_runs_2a], [extract_run_df(r, tuple(keys)) for r in cifar10_runs_2a]))# convert keys to tuple to allow LRU cache to be used\n",
    "print(\"cifar\")\n",
    "cinic10_runs_2a = [*filter_runs_by_tag(\"cinic10\", api.runs(\"goldiprox/cinic10\")), *filter_runs_by_tag(\"cinic10\", api.runs(\"goldiprox/svp_final\"))]\n",
    "cinic10_runs_all_info = list(zip(cinic10_runs_2a, [run_to_selection_method(r) for r in cinic10_runs_2a], [extract_run_df(r, tuple(keys)) for r in cinic10_runs_2a]))# convert keys to tuple to allow LRU cache to be used\n",
    "print(\"cinic\")\n",
    "cifar100_runs_2a = [*filter_runs_by_tag(\"cifar100\", api.runs(\"goldiprox/cifar100\")), *filter_runs_by_tag(\"cifar100\", api.runs(\"goldiprox/svp_final\"))]\n",
    "cifar100_runs_all_info = list(zip(cifar100_runs_2a, [run_to_selection_method(r) for r in cifar100_runs_2a], [extract_run_df(r, tuple(keys)) for r in cifar100_runs_2a]))\n",
    "print(\"cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c6791e-c82f-4fe2-9ede-5fa7a6a3b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar\n"
     ]
    }
   ],
   "source": [
    "keys = [\"trainer/global_step\", \"val_acc_epoch\"]\n",
    "cifar10_runs_2a = [*filter_runs_by_tag(\"paper\", api.runs(\"mtrazzak/clothing1m-samedist\"))]\n",
    "cifar10_runs_all_info = list(zip(cifar10_runs_2a, [run_to_selection_method(r) for r in cifar10_runs_2a], [extract_run_df(r, tuple(keys)) for r in cifar10_runs_2a]))# convert keys to tuple to allow LRU cache to be used\n",
    "print(\"cifar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad1e835-1659-4211-9127-732cc64d5c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4990912682734097"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_speedup(cifar10_runs_all_info, \"Uniform Sampling\", \"Reducible Loss (Ours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61df916-1296-46ea-9794-0fdfd57320fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure2a_subplot(selection_methods, runs_all_info, ylim):\n",
    "    for sm_i, sm in enumerate(selection_methods):\n",
    "        sm_dfs = [d for _, c, d in runs_all_info if c == sm]\n",
    "                \n",
    "        if len(sm_dfs) == 0:\n",
    "            print(f\"Could not find any dfs corresponding to {sm}\")\n",
    "            continue\n",
    "            \n",
    "        x_vals = df_to_xvals(sm_dfs[0])\n",
    "        y_vals = np.zeros(shape=(x_vals.size, len(sm_dfs)))\n",
    "\n",
    "        for sm_df_i, sm_df in enumerate(sm_dfs):\n",
    "            acc = 100*sm_df[\"val_acc_epoch\"].to_numpy()\n",
    "            y_vals[:acc.size, sm_df_i] = acc\n",
    "        \n",
    "        plt.plot(x_vals, np.mean(y_vals, axis=-1), color=selection_methods_color_dict[sm], linewidth=1, label=sm)\n",
    "        plt.fill_between(x_vals, np.min(y_vals, axis=-1), np.max(y_vals, axis=-1), color=selection_methods_color_dict[sm], alpha=0.15, linewidth=0)\n",
    "        plt.xlabel(\"Steps\", fontsize=10)\n",
    "        \n",
    "        plt.ylabel(\"Test Accuracy (%)\", fontsize=10)\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.ylim(ylim)\n",
    "        plt.xlim([np.min(x_vals), np.max(x_vals)])\n",
    "        \n",
    "def figure2a_subplot_alt(selection_methods, runs_all_info, xlim):\n",
    "    for sm_i, sm in enumerate(selection_methods):\n",
    "        sm_dfs = [d for _, c, d in runs_all_info if c == sm]\n",
    "        print(sm)\n",
    "        if len(sm_dfs) == 0:\n",
    "            print(f\"Could not find any dfs corresponding to {sm}\")\n",
    "            continue\n",
    "            \n",
    "        x_vals = df_to_xvals(sm_dfs[0])\n",
    "        acc_vals = np.zeros(shape=(x_vals.size, len(sm_dfs)))\n",
    "\n",
    "        for sm_df_i, sm_df in enumerate(sm_dfs):\n",
    "            acc_vals[:, sm_df_i] = 100*sm_df[\"val_acc_epoch\"].to_numpy()\n",
    "            \n",
    "        xrange = np.linspace(xlim[0], xlim[1], 50)\n",
    "        steps_needed = np.zeros((xrange.size, len(sm_dfs)))\n",
    "                \n",
    "        for i, acc in enumerate(xrange):\n",
    "            for j in range(len(sm_dfs)):\n",
    "                exceeded_acc = acc_vals[:, j] > acc\n",
    "                if np.sum(exceeded_acc) > 0: # i.e., we exceeded the accuracy\n",
    "                    steps_needed[i, j] = x_vals[np.nonzero(exceeded_acc)[0][0]]\n",
    "                else:\n",
    "                    steps_needed[i, j] = np.nan\n",
    "                    \n",
    "        plt.plot(xrange, np.mean(steps_needed, axis=-1), color=selection_methods_color_dict[sm], linewidth=1.5, label=sm)\n",
    "        plt.fill_between(xrange, np.min(steps_needed, axis=-1), np.max(steps_needed, axis=-1), color=selection_methods_color_dict[sm], alpha=0.15, linewidth=0)\n",
    "        plt.ylabel(\"Steps Required\\nLower is Better\", fontsize=10)\n",
    "        \n",
    "        plt.xlabel(\"Target Accuracy (%)\", fontsize=10)\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.xlim(xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6c758-192e-4073-aafc-4304cd96ed1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 2), dpi=300)\n",
    "plt.subplot(131)\n",
    "figure2a_subplot(selection_methods, cifar10_runs_all_info, [0, 100])\n",
    "plt.title(\"CIFAR10\", fontsize=10)\n",
    "print(compute_speedup(cifar10_runs_all_info, \"Uniform Sampling\", \"Reducible Loss (Ours)\"))\n",
    "plt.subplot(132)\n",
    "figure2a_subplot(selection_methods, cifar100_runs_all_info, [0, 70])\n",
    "plt.title(\"CIFAR100\", fontsize=10)\n",
    "print(compute_speedup(cifar100_runs_all_info, \"Uniform Sampling\", \"Reducible Loss (Ours)\"))\n",
    "plt.subplot(133)\n",
    "figure2a_subplot(selection_methods, cinic10_runs_all_info, [10, 90])\n",
    "plt.title(\"CINIC10\", fontsize=10)\n",
    "print(compute_speedup(cinic10_runs_all_info, \"Uniform Sampling\", \"Reducible Loss (Ours)\"))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure_outputs/figure2a_alt.pdf\", bbox_inches='tight')\n",
    "plt.legend(fancybox=True, shadow=True, fontsize=8, ncol=3, bbox_to_anchor=(-1, -0.35), loc=\"upper center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1911f-8275-4bb8-bc8a-133855a4acb9",
   "metadata": {},
   "source": [
    "# Figure 2a—alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad55bf5-2ed3-4f82-9dfe-789d494c7cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 2), dpi=300)\n",
    "plt.subplot(131)\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info, [0, 110])\n",
    "plt.title(\"(a) CIFAR10\", fontsize=10)\n",
    "print(f\"CIFAR10 speedup: {compute_speedup(cifar10_runs_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(132)\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info, [0, 70])\n",
    "plt.title(\"(b) CIFAR100\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "print(f\"CIFAR100 speedup: {compute_speedup(cifar100_runs_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(133)\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info, [0, 90])\n",
    "plt.title(\"(c) CINIC10\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "plt.ylim([0, 20000])\n",
    "print(f\"CINIC10 speedup: {compute_speedup(cinic10_runs_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(fancybox=True, shadow=True, fontsize=8, ncol=3, bbox_to_anchor=(-1, -0.35), loc=\"upper center\")\n",
    "plt.savefig(\"figure_outputs/figure_2a.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae977a1-8678-400c-b428-8b4d86945036",
   "metadata": {},
   "source": [
    "# Figure 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f396db-f5e7-422e-868e-9eba8a32622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_runs_2b = [*get_runs_by_tag_quick(\"goldiprox/jb_cifar10\", \"cifar10_labelnoise\"), *get_runs_by_tag_quick(\"goldiprox/svp_final\", \"cifar10_labelnoise\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c02f3-e274-46cb-bffe-331cae05211d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"val_acc_epoch\"]\n",
    "\n",
    "# cifar10_runs_2b = [*filter_runs_by_tag(\"cifar10_labelnoise\", api.runs(\"goldiprox/jb_cifar10\")), *filter_runs_by_tag(\"cifar10_labelnoise\", api.runs(\"goldiprox/svp_final\"))]\n",
    "cifar10_runs_2b = [*get_runs_by_tag_quick(\"goldiprox/jb_cifar10\", \"cifar10_labelnoise\"), *get_runs_by_tag_quick(\"goldiprox/svp_final\", \"cifar10_labelnoise\")]\n",
    "cifar10_runs_all_info_2b = list(zip(cifar10_runs_2b, [run_to_selection_method(r) for r in cifar10_runs_2b], [extract_run_df(r, tuple(keys)) for r in cifar10_runs_2b]))# convert keys to tuple to allow LRU cache to be used\n",
    "print(\"cifar10\")\n",
    "# cinic10_runs_2b = [*filter_runs_by_tag(\"cinic10_labelnoise\", api.runs(\"goldiprox/cinic10\")), *filter_runs_by_tag(\"cinic10_labelnoise\", api.runs(\"goldiprox/svp_final\"))]\n",
    "cinic10_runs_2b = [*get_runs_by_tag_quick(\"goldiprox/cinic10\", \"cinic10_labelnoise\"), *get_runs_by_tag_quick(\"goldiprox/svp_final\", \"cinic10_labelnoise\")]\n",
    "cinic10_runs_all_info_2b = list(zip(cinic10_runs_2b, [run_to_selection_method(r) for r in cinic10_runs_2b], [extract_run_df(r, tuple(keys)) for r in cinic10_runs_2b]))# convert keys to tuple to allow LRU cache to be used\n",
    "print(\"cinic10\")\n",
    "cifar100_runs_2b = [*get_runs_by_tag_quick(\"goldiprox/cifar100\", \"cifar100_labelnoise\"), *get_runs_by_tag_quick(\"goldiprox/svp_final\", \"cifar100_labelnoise\")]\n",
    "# cifar100_runs_2b = [*filter_runs_by_tag(\"cifar100_labelnoise\", api.runs(\"goldiprox/cifar100\")), *filter_runs_by_tag(\"cifar100_labelnoise\", api.runs(\"goldiprox/svp_final\"))]\n",
    "cifar100_runs_all_info_2b = list(zip(cifar100_runs_2b, [run_to_selection_method(r) for r in cifar100_runs_2b], [extract_run_df(r, tuple(keys)) for r in cifar100_runs_2b]))\n",
    "print(\"cifar10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48636cb6-0c2a-4bbf-93ad-beb269992761",
   "metadata": {},
   "source": [
    "# Figure 2b – alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f75f3e-faec-4301-98dc-ee71e28dafd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 2), dpi=300)\n",
    "plt.subplot(131)\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info_2b, [0, 110])\n",
    "plt.title(\"CIFAR10\", fontsize=10)\n",
    "print(f\"CIFAR10 speedup: {compute_speedup(cifar10_runs_all_info_2b, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(132)\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info_2b, [0, 70])\n",
    "plt.title(\"CIFAR100\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "print(f\"CIFAR100 speedup: {compute_speedup(cifar100_runs_all_info_2b, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(133)\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info_2b, [0, 90])\n",
    "print(f\"CINIC10 speedup: {compute_speedup(cinic10_runs_all_info_2b, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.title(\"CINIC10\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "plt.tight_layout()\n",
    "# plt.legend(fancybox=True, shadow=True, fontsize=8, ncol=3, bbox_to_anchor=(-1, -0.35), loc=\"upper center\")\n",
    "plt.savefig(\"figure_outputs/figure_2b.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f40f21-1d5a-4cea-9490-eec6f259cb64",
   "metadata": {},
   "source": [
    "# Figure 2 Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a882dc3-3100-4806-8007-8411de647ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 3.75), dpi=300)\n",
    "plt.subplot(231)\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info, [0, 110])\n",
    "plt.title(\"Half of CIFAR10\", fontsize=10)\n",
    "plt.xlabel(None)\n",
    "print(f\"CIFAR10 speedup: {compute_speedup(cifar10_runs_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(232)\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info, [0, 70])\n",
    "plt.title(\"Half of CIFAR100\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "print(f\"CIFAR100 speedup: {compute_speedup(cifar100_runs_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "splt = plt.subplot(233)\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info, [0, 90])\n",
    "plt.title(\"CINIC10\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.ylim([0, 20000])\n",
    "print(f\"CINIC10 speedup: {compute_speedup(cinic10_runs_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "\n",
    "plt.subplot(234)\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info_2b, [0, 100])\n",
    "plt.title(\"Half of CIFAR10\\n(Label Noise)\", fontsize=10)\n",
    "print(f\"CIFAR10 speedup: {compute_speedup(cifar10_runs_all_info_2b, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(235)\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info_2b, [0, 70])\n",
    "plt.title(\"Half of CIFAR100\\n(Label Noise)\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "print(f\"CIFAR100 speedup: {compute_speedup(cifar100_runs_all_info_2b, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.subplot(236)\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info_2b, [0, 90])\n",
    "print(f\"CINIC10 speedup: {compute_speedup(cinic10_runs_all_info_2b, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.title(\"CINIC10\\n(Label Noise)\", fontsize=10)\n",
    "plt.ylabel(None)\n",
    "plt.ylim([0, 20000])\n",
    "plt.tight_layout()\n",
    "\n",
    "splt.legend(fancybox=True, shadow=True, fontsize=8, ncol=3, bbox_to_anchor=(-1, -2.05), loc=\"upper center\")\n",
    "plt.savefig(\"figure_outputs/figure_2_combined.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813662e-1077-4246-b8cd-471ff4fe7a17",
   "metadata": {},
   "source": [
    "# Clothing1M Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974c7a3-a778-47ba-aef8-0b4a489b3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"val_acc_epoch\"]\n",
    "\n",
    "clothing_1m_runs = [*filter_runs_by_tag(\"paper\", api.runs(\"mtrazzak/clothing1m-cleantrain\"))]\n",
    "clothing_1m_runs_all_info = list(zip(clothing_1m_runs, [run_to_selection_method(r) for r in clothing_1m_runs], [extract_run_df(r, tuple(keys)) for r in clothing_1m_runs]))# convert keys to tuple to allow LRU cache to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b17018-607c-4adf-b95a-8215d2717aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_all_info_dict = {\n",
    "    \"clothing_1m_runs_all_info\": clothing_1m_runs_all_info,\n",
    "    \"cinic10_runs_all_info\": cinic10_runs_all_info,\n",
    "    \"cinic10_runs_all_info_2b\": cinic10_runs_all_info_2b,\n",
    "    \"cifar10_runs_all_info\": cifar10_runs_all_info,\n",
    "    \"cifar10_runs_all_info_2b\": cifar10_runs_all_info_2b,\n",
    "    \"cifar100_runs_all_info\": cifar100_runs_all_info,\n",
    "    \"cifar100_runs_all_info_2b\": cifar100_runs_all_info_2b,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba9ac7-a602-43d5-8220-12dcab2c861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"all_runs_all_info_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_runs_all_info_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e50c37-8be4-4684-9f5a-403ff2ede74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_speedup(clothing_1m_runs_all_info, \"Uniform Sampling\", \"Reducible Loss (Ours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc407b0a-7a44-4981-8ca4-0254783efd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5, 3.5), dpi=300)\n",
    "figure2a_subplot_alt(selection_methods, clothing_1m_runs_all_info, [0, 100])\n",
    "plt.title(\"Clothing-1M\")\n",
    "plt.legend(fontsize=8, loc=\"upper right\")\n",
    "plt.savefig(\"figure_outputs/clothing_1m.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b760080-1630-445b-93ea-54460245cf19",
   "metadata": {},
   "source": [
    "# Figure 3 Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bbd7f-4c96-4fc2-a42a-6641cd5eb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6484f2-8669-4a7a-9da5-867f6282667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5.75, 2.75), dpi=300)\n",
    "gs = GridSpec(2, 5, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info, [0, 100])\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10\", fontsize=7)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info, [0, 70])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10\", fontsize=7)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info, [0, 90])\n",
    "plt.yticks([0, 20000], [\"0\", \"2$\\cdot$10$^4$\"], fontsize=6)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.title(\"CIFAR10\", fontsize=7)\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info_2b, [0, 100])\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10\", fontsize=7)\n",
    "plt.xlabel(\"Target accuracy (%)\", fontsize=7)\n",
    "\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info_2b, [0, 70])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10\", fontsize=7)\n",
    "plt.xlabel(\"Target accuracy (%)\", fontsize=7)\n",
    "\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info_2b, [0, 90])\n",
    "plt.yticks([0, 20000], [\"0\", \"2$\\cdot$10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.title(\"CIFAR10\", fontsize=7)\n",
    "plt.xlabel(\"Target accuracy (%)\", fontsize=7)\n",
    "\n",
    "\n",
    "ax7 = fig.add_subplot(gs[:, -2:])\n",
    "figure2a_subplot_alt(selection_methods, clothing_1m_runs_all_info, [0, 100])\n",
    "plt.plot([-10, -10], [0, 0], label=\"SVP\", color=selection_methods_color_dict[\"SVP\"])\n",
    "plt.plot([-10, -10], [0, 0], label=\"Gradient Norm IS\", color=selection_methods_color_dict[\"Gradient Norm IS\"])\n",
    "plt.yticks([0, 75000, 150000], [\"0\", \"75$\\cdot$10$^3$\", \"15$\\cdot$10$^4$\"], fontsize=8)\n",
    "plt.title(\"Clothing-1M\")\n",
    "plt.legend(fontsize=8, loc=\"upper right\", shadow=True, fancybox=True, bbox_to_anchor=(1.1, 1.1))\n",
    "plt.ylabel(None)\n",
    "plt.ylabel(\"Steps required to reach target accuracy\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483d9f4-f4a6-4697-bd6c-64e5a526a0ca",
   "metadata": {},
   "source": [
    "# Figure 3 Combined V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74718649-f337-4910-824c-bb3b144f2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c03b75-936d-4cd6-ab19-8be6b6f62c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5.75, 4.25), dpi=300)\n",
    "gs = GridSpec(3, 4, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0, 2])\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info, [0, 100])\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10\", fontsize=8)\n",
    "plt.ylabel(\"Steps required\", fontsize=7)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[1, 2])\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info, [0, 70])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR100\", fontsize=8)\n",
    "plt.ylabel(\"Steps required\", fontsize=7)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[2, 2])\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info, [0, 90])\n",
    "# plt.yticks([0, 20000], [\"0\", \"2$\\cdot$10$^4$\"], fontsize=6)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.title(\"CINIC10\", fontsize=8)\n",
    "plt.xlabel(\"Target Accuracy (%)\", fontsize=7)\n",
    "plt.ylabel(\"Steps required\", fontsize=7)\n",
    "\n",
    "ax4 = fig.add_subplot(gs[0, 3])\n",
    "figure2a_subplot_alt(selection_methods, cifar10_runs_all_info_2b, [0, 100])\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10 (Label Noise)\", fontsize=8)\n",
    "\n",
    "ax5 = fig.add_subplot(gs[1, 3])\n",
    "figure2a_subplot_alt(selection_methods, cifar100_runs_all_info_2b, [0, 70])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.title(\"CIFAR10 (Label Noise)\", fontsize=8)\n",
    "\n",
    "ax6 = fig.add_subplot(gs[2, 3])\n",
    "figure2a_subplot_alt(selection_methods, cinic10_runs_all_info_2b, [0, 90])\n",
    "plt.yticks([0, 10000], [\"0\", \"10$^4$\"], fontsize=6)\n",
    "plt.xticks(fontsize=6)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "plt.title(\"CINIC10 (Label Noise)\", fontsize=8)\n",
    "plt.xlabel(\"Target Accuracy (%)\", fontsize=7)\n",
    "\n",
    "\n",
    "ax7 = fig.add_subplot(gs[:-1, :2])\n",
    "figure2a_subplot_alt(selection_methods, clothing_1m_runs_all_info, [0, 80])\n",
    "plt.yticks([0, 75000, 150000], [\"0\", \"75$\\cdot$10$^3$\", \"15$\\cdot$10$^4$\"], fontsize=8)\n",
    "\n",
    "plt.plot([-10, -10], [0, 0], label=\"SVP\", color=selection_methods_color_dict[\"SVP\"])\n",
    "plt.plot([-10, -10], [0, 0], label=\"Gradient Norm IS\", color=selection_methods_color_dict[\"Gradient Norm IS\"])\n",
    "plt.title(\"Clothing-1M\")\n",
    "plt.ylabel(\"Steps required to reach target accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=7, loc=\"upper center\", bbox_to_anchor=(0.5, -0.225), shadow=True, fancybox=True, handlelength=0.75, \n",
    "           borderpad=0.5, handletextpad=0.5, ncol=2, title=\"Selection Method\")\n",
    "plt.savefig('figure_outputs/figure_3_large.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13328e8-188e-40e2-a4da-95b283d99ae8",
   "metadata": {},
   "source": [
    "# Figure Relevance Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa99cee-5b3a-4570-899c-339b84e1bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"val_acc_epoch\", \"percentage_relevant_epoch\"]\n",
    "\n",
    "cinic10_relevance_runs = filter_runs_by_tag(\"cinic10_relevance\", api.runs(\"goldiprox/cinic10_relevance\"))\n",
    "cinic10_relevance_all_info = list(zip(cinic10_relevance_runs, \n",
    "                             [run_to_selection_method(r) for r in cinic10_relevance_runs], \n",
    "                             [extract_run_df(r, tuple(keys)) for r in cinic10_relevance_runs]))# convert keys to tuple to allow LRU cache to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbae4f8-97a8-4a5a-af1e-b368cd014351",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer\\global_step\", \"val_acc_epoch\", \"percentage_relevant_epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13895cbd-50f7-46d7-9c55-59a27b1419ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_run_df(cinic10_relevance_runs[-1], tuple(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e540d-abf5-4628-a2ad-8b2275679ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cinic10_relevance_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e694a-580c-457e-93de-2b9edd82fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cinic10_relevance_all_info[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f0944-2052-4f71-82e5-d1db503b6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.75, 2.25), dpi=300)\n",
    "plt.subplot(121)\n",
    "figure2a_subplot_alt(selection_methods, cinic10_relevance_all_info, [0, 100])\n",
    "\n",
    "plt.subplot(122)\n",
    "for sm_i, sm in enumerate(selection_methods):\n",
    "    sm_dfs = [d for _, c, d in cinic10_relevance_all_info if c == sm]\n",
    "\n",
    "    if len(sm_dfs) == 0:\n",
    "        print(f\"Could not find any dfs corresponding to {sm}\")\n",
    "        continue\n",
    "\n",
    "    x_vals = df_to_xvals(sm_dfs[0])\n",
    "   \n",
    "    acc = 100*sm_dfs[0][\"percentage_relevant_epoch\"].to_numpy()\n",
    "    acc_mask = ~np.isnan(acc)\n",
    "    x_vals = x_vals[acc_mask]\n",
    "    y_vals = np.zeros(shape=(x_vals.size, len(sm_dfs)))\n",
    "    \n",
    "    for sm_df_i, sm_df in enumerate(sm_dfs):\n",
    "        acc = 100*sm_df[\"percentage_relevant_epoch\"].to_numpy()\n",
    "        acc_masked = acc[~np.isnan(acc)]\n",
    "        y_vals[:acc_masked.size, sm_df_i] = acc_masked\n",
    "    \n",
    "    marker = \"o\" if sm == \"Reducible Loss (Ours)\" else None\n",
    "        \n",
    "    plt.plot(x_vals, np.median(y_vals, axis=-1), color=selection_methods_color_dict[sm], linewidth=1, label=sm, marker=marker, markevery=10, markersize=2)\n",
    "    plt.fill_between(x_vals, np.min(y_vals, axis=-1), np.max(y_vals, axis=-1), color=selection_methods_color_dict[sm], alpha=0.15, linewidth=0)\n",
    "    plt.xlabel(\"Steps\", fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Percentage of selected\\npoints relevant (%)\", fontsize=10)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlim([np.min(x_vals), np.max(x_vals)])\n",
    "plt.tight_layout()\n",
    "plt.legend(ncol=3, loc=\"upper center\", bbox_to_anchor=(-0.15, -0.25), shadow=True, fancybox=True)\n",
    "print(f\"CINIC10 speedup: {compute_speedup(cinic10_relevance_all_info, 'Uniform Sampling', 'Reducible Loss (Ours)'):.2f}\")\n",
    "plt.savefig(\"figure_outputs/figure_relevance.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b7b8f-2c64-4e4d-a46c-6c206c54aaba",
   "metadata": {},
   "source": [
    "# Figure Irred Loss Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7b303-f2f8-4a46-a5be-57fdc7d1f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_info_dict = {\n",
    "        \"uniform\" : (\"Uniform Sampling\", \"\"),\n",
    "        \"resnet_4\": (\"Resnet-18\", 0, \"Epoch 4\", colors[0]),\n",
    "        \"resnet_7\": (None, 0.25, \"Epoch 7\", colors[0]),\n",
    "        \"best_loss_resnet\": (None, 0.5, \"Epoch 47 (Best Loss)\", colors[0]),\n",
    "        \"resnet_best_acc\": (None, 0.75, \"Epoch 91 (Best Accuracy)\", colors[0]),\n",
    "        \"small_cnn_6\": (\"Small CNN\", 1.25, \"Epoch 6\", colors[1]),\n",
    "        \"small_cnn_16\": (None, 1.5, \"Epoch 16\", colors[1]),\n",
    "        \"small_cnn_best_loss\": (None, 1.75, \"Epoch 38 (Best Loss)\", colors[1]),\n",
    "        \"small_cnn_best_acc\": (None, 2, \"Epoch 86 (Best Accuracy)\", colors[1]),\n",
    "}\n",
    "\n",
    "    \n",
    "def get_info_from_run(run):    \n",
    "    for k, v in tag_info_dict.items():\n",
    "        if k in run.tags:\n",
    "            return v\n",
    "    \n",
    "bars = []\n",
    "    \n",
    "    \n",
    "keys = [\"trainer/global_step\", \"val_acc_epoch\"]\n",
    "\n",
    "irred_loss_ablation_runs = filter_runs_by_tag(\"irred_loss_ablation\", api.runs(\"goldiprox/jb_cifar10\"))\n",
    "irred_loss_ablation_all_info = list(zip(irred_loss_ablation_runs, \n",
    "                             [get_info_from_run(r) for r in irred_loss_ablation_runs], \n",
    "                             [extract_run_df(r, tuple(keys)) for r in irred_loss_ablation_runs]))\n",
    "\n",
    "n_epochs = 100\n",
    "baseline_dfs = [df for _, n, df in irred_loss_ablation_all_info if n[0] == \"Uniform Sampling\"]\n",
    "uniform_acc_n_epochs = np.mean([df[\"val_acc_epoch\"].to_numpy()[n_epochs-1] for df in baseline_dfs])\n",
    "\n",
    "plt.figure(figsize=(2.7, 1.25), dpi=300)\n",
    "\n",
    "ablations = list(tag_info_dict.values())[1:]\n",
    "for a_i, ablation in enumerate(ablations):\n",
    "    ablation_dfs = [df for _, n, df in irred_loss_ablation_all_info if n == ablation]\n",
    "    ablation_infos = [n for _, n, df in irred_loss_ablation_all_info if n == ablation]\n",
    "#     ablation_acc_vals = np.zeros(shape=(n_epochs, len(ablation_dfs)))\n",
    "#     ablation_epochs_taken = np.zeros(shape=len(ablation_dfs))\n",
    "    \n",
    "#     for a_i_j, ablation_df in enumerate(ablation_dfs):\n",
    "#         val_acc = ablation_df[\"val_acc_epoch\"].to_numpy()\n",
    "        \n",
    "#         nzs = np.nonzero(val_acc > uniform_acc_n_epochs)[0]\n",
    "#         if len(nzs > 0):\n",
    "#             epoch_taken = nzs[0]\n",
    "#         else:\n",
    "#             epoch_taken = np.nan\n",
    "        \n",
    "        \n",
    "#         if val_acc.size > n_epochs:\n",
    "#             ablation_acc_vals[:, a_i_j] = val_acc[:n_epochs]\n",
    "            \n",
    "#         ablation_epochs_taken[a_i_j] = epoch_taken\n",
    "    \n",
    "    y_val = ablation_infos[0][1]\n",
    "    speedup = compute_speedup(irred_loss_ablation_all_info, (\"Uniform Sampling\", \"\"), ablation)\n",
    "    plt.xlim([0, 5])\n",
    "    plt.barh(y_val, speedup, height=0.25, color=ablation_infos[0][3], edgecolor=\"k\", linewidth=1, label=ablation_infos[0][0])\n",
    "    if np.isnan(np.mean(ablation_epochs_taken)):\n",
    "        plt.text(0.01, y_val, \"$\\infty$\", ha='left', va='center')\n",
    "    \n",
    "    \n",
    "ytick_vals = [i[1] for k, i in list(tag_info_dict.items())[1:]]\n",
    "ytick_labels = [i[2] for k, i in list(tag_info_dict.items())[1:]]\n",
    "plt.yticks(ytick_vals, ytick_labels, fontsize=8)\n",
    "plt.xlabel(\"Speedup\")\n",
    "plt.legend(loc=\"upper right\", fontsize=7, fancybox=True, shadow=True, bbox_to_anchor=(1.01, 1.05))\n",
    "plt.title(\"CIFAR10 Irreducible Loss\\nModel Ablation\", fontsize=10)\n",
    "plt.savefig(\"figure_outputs/irreducible_loss_model_ablation.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6318b2-9419-4532-8dd6-b4e34e39d019",
   "metadata": {},
   "source": [
    "# Figure Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ae0c7-29b5-4653-88f1-f87cc4c3e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"trainer/global_step\", \"val_acc_epoch\"]\n",
    "\n",
    "cifar100_ablation_runs = [*filter_runs_by_tag(\"cifar100_ablation\", api.runs(\"goldiprox/cifar100\")), \n",
    "                          *filter_runs_by_tag(\"cifar100_ablation\", api.runs(\"goldiprox/cifar_update_irreducible\"))]\n",
    "\n",
    "cifar100_runs_all_info = list(zip(cifar100_ablation_runs, [run_to_selection_method(r) for r in cifar100_ablation_runs], [extract_run_df(r, tuple(keys)) for r in cifar100_ablation_runs]))\n",
    "\n",
    "cifar10_ablation_runs = filter_runs_by_tag(\"cifar10_ablation\", api.runs(\"goldiprox/jb_cifar10\"))\n",
    "cifar10_runs_all_info = list(zip(cifar10_ablation_runs, [run_to_selection_method(r) for r in cifar10_ablation_runs], [extract_run_df(r, tuple(keys)) for r in cifar10_ablation_runs]))\n",
    "\n",
    "\n",
    "cinic10_ablation_runs = filter_runs_by_tag(\"cinic10_ablation\", api.runs(\"goldiprox/goldiprox\"))\n",
    "cinic10_runs_all_info = list(zip(cinic10_ablation_runs, [run_to_selection_method(r) for r in cinic10_ablation_runs], [extract_run_df(r, tuple(keys)) for r in cinic10_ablation_runs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea715f2b-babf-4ea5-92d2-6b91c66b08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablations = {\n",
    "    'Reducible Loss (Ours) 0.05': {\n",
    "        'baseline': 'Uniform Sampling 0.05',\n",
    "        \"label\": \"5%\",\n",
    "        \"color\": colors[0],\n",
    "    },\n",
    "    'Reducible Loss (Ours) 0.1': {\n",
    "        'baseline': 'Uniform Sampling 0.1',\n",
    "        \"label\" : \"10%\",\n",
    "        \"color\": colors[1],\n",
    "    },\n",
    "    'Reducible Loss (Ours) 0.15': {\n",
    "        'baseline': 'Uniform Sampling 0.15',\n",
    "        \"label\" : \"15%\",\n",
    "        \"color\": colors[2],\n",
    "    },\n",
    "    'Reducible Loss (Ours) 0.2': {\n",
    "        'baseline': 'Uniform Sampling 0.2',\n",
    "        \"label\" : \"20%\",\n",
    "        \"color\": colors[3],\n",
    "    }\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(2.75, 1.25), dpi=300)\n",
    "\n",
    "datasets = [cifar100_runs_all_info, cifar10_runs_all_info, cinic10_runs_all_info]\n",
    "dataset_names = [\"CIFAR100\", \"CIFAR10\", \"CINIC10\"]\n",
    "for d_i, dataset in enumerate(datasets):\n",
    "    for ab_i, (ab, ab_dict) in enumerate(ablations.items()):\n",
    "        if d_i == 2:\n",
    "            speedup = compute_speedup_legacy(dataset, \"Uniform Sampling 0.1\", ab)\n",
    "        else:\n",
    "            speedup = compute_speedup_legacy(dataset, ab_dict[\"baseline\"], ab)\n",
    "            \n",
    "        plt.barh(d_i+(1+ab_i)*1.0/(1+len(ablations.keys())), speedup, 1.0/(1+len(ablations.keys())), \n",
    "                 label=ab_dict[\"label\"] if d_i==0 else None, color=ab_dict[\"color\"]) \n",
    "plt.yticks([0.5, 1.5, 2.5], dataset_names)\n",
    "plt.legend(fontsize=7, ncol=2, title=\"Percentage Selected\", title_fontsize=9)\n",
    "plt.xlabel(\"Speedup\", fontsize=8)\n",
    "plt.savefig(\"figure_outputs/figure_percent_selected.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
